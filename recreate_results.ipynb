{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-seed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Required Libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from split import deterministic_split, random_split\n",
    "from image_dataset import ImageDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None, synthetic_label=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_files (list): List of file paths for images.\n",
    "            labels (list, optional): List of labels corresponding to the image files.\n",
    "                                     If None, labels will be inferred based on folder names.\n",
    "            transform (callable, optional): Transform to apply to the images.\n",
    "            synthetic_label (int, optional): Label to assign all images if labels are not provided.\n",
    "        \"\"\"\n",
    "        self.image_paths = file_list\n",
    "        self.transform = transform\n",
    "        self.synthetic_label = synthetic_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.synthetic_label\n",
    "\n",
    "        try:\n",
    "            # Load the image and convert to RGB\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "            label = -1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Use the synthetic_label if provided, otherwise use the inferred label\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Train Model Function\n",
    "def train_model(datasets, variants, model_name, base_dir=\"/dtu/blackhole/12/145234/\", num_epochs=10, batch_size=32, learning_rate=0.001):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Prepare datasets\n",
    "    _datasets = []\n",
    "    for dataset, variant in zip(datasets, variants):\n",
    "        target_dir = os.path.join(base_dir, f\"{dataset}/{variant}\")\n",
    "        \n",
    "        if variant == \"real-fewshot\":\n",
    "            target_dir = os.path.join(target_dir, \"best\" if dataset == \"cars\" else \"seed0\")\n",
    "            train_files, _ = deterministic_split(target_dir, test_ratio=0.2)\n",
    "        else:\n",
    "            target_dir = os.path.join(target_dir, \"train\")\n",
    "            train_files, _ = random_split(target_dir, train_count=2514 if dataset == \"cars\" else 471)\n",
    "        \n",
    "        dataset_obj = ImageDataset(file_list=train_files, transform=train_transform, synthetic_label=1 if variant != \"real-fewshot\" else 0)\n",
    "        _datasets.append(dataset_obj)\n",
    "    \n",
    "    combined_dataset = ConcatDataset(_datasets)\n",
    "    dataloader_train = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader_train, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            correct_predictions += torch.sum(preds == labels.data)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss / len(combined_dataset):.4f}, Accuracy: {correct_predictions.double() / len(combined_dataset):.4f}\")\n",
    "    \n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), f\"models/{model_name}.pth\")\n",
    "    print(f\"Model saved to models/{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-transforms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Evaluate Model Function\n",
    "def evaluate_model(model_name, datasets, variants, base_dir=\"small_dataset\", batch_size=32):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    _datasets = []\n",
    "    for dataset, variant in zip(datasets, variants):\n",
    "        target_dir = os.path.join(base_dir, f\"{dataset}/{variant}\")\n",
    "        \n",
    "        if variant == \"real-fewshot\":\n",
    "            target_dir = os.path.join(target_dir, \"best\" if dataset == \"cars\" else \"seed0\")\n",
    "            _, test_files = deterministic_split(target_dir, test_ratio=0.2)\n",
    "        else:\n",
    "            target_dir = os.path.join(target_dir, \"train\")\n",
    "            _, test_files = random_split(target_dir, n_train=2514 if dataset == \"cars\" else 471)\n",
    "        \n",
    "        dataset_obj = ImageDataset(file_list=test_files, transform=test_transform, synthetic_label=1 if variant != \"real-fewshot\" else 0)\n",
    "        _datasets.append(dataset_obj)\n",
    "    \n",
    "    combined_dataset = ConcatDataset(_datasets)\n",
    "    dataloader_test = DataLoader(combined_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    model.load_state_dict(torch.load(f\"models/{model_name}.pth\", map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader_test, desc=\"Inference\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    report = classification_report(all_labels, all_preds, output_dict=True, target_names=[\"Real\", \"Synthetic\"])\n",
    "    metrics = {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"class_0\": report[\"Real\"],\n",
    "        \"class_1\": report[\"Synthetic\"]\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Main Script to Train and Evaluate Models\n",
    "train_datasets = [\n",
    "    [(\"cars\", \"sd2.1\"), (\"cars\", \"real-fewshot\")],\n",
    "    [(\"pets\", \"sd2.1\"), (\"pets\", \"real-fewshot\")],\n",
    "    [(\"cars\", \"sd2.1\"), (\"pets\", \"sd2.1\"), (\"cars\", \"real-fewshot\"), (\"pets\", \"real-fewshot\")]\n",
    "]\n",
    "\n",
    "eval_datasets = [\n",
    "    [(\"cars\", \"dd-fewshot\"), (\"cars\", \"real-fewshot\")],\n",
    "    [(\"cars\", \"sd2.1\"), (\"cars\", \"real-fewshot\")],\n",
    "    [(\"pets\", \"sd2.1\"), (\"pets\", \"real-fewshot\")],\n",
    "    [(\"pets\", \"dd-fewshot\"), (\"pets\", \"real-fewshot\")]\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for train_combination in train_datasets:\n",
    "    combined_name = \"__\".join([f\"{dataset}_{variant}\" for dataset, variant in train_combination])\n",
    "    model_name = f\"combined_{combined_name}\"\n",
    "    \n",
    "    if not os.path.exists(f\"models/{model_name}.pth\"):\n",
    "        train_model(\n",
    "            datasets=[dataset for dataset, variant in train_combination],\n",
    "            variants=[variant for dataset, variant in train_combination],\n",
    "            model_name=model_name\n",
    "        )\n",
    "    \n",
    "    for eval_combination in eval_datasets:\n",
    "        eval_name = \"__\".join([f\"{dataset}_{variant}\" for dataset, variant in eval_combination])\n",
    "        metrics = evaluate_model(\n",
    "            model_name=model_name,\n",
    "            datasets=[dataset for dataset, variant in eval_combination],\n",
    "            variants=[variant for dataset, variant in eval_combination]\n",
    "        )\n",
    "        results[(model_name, eval_name)] = metrics\n",
    "\n",
    "# Save results to CSV\n",
    "import csv\n",
    "with open(\"results.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Trained_On\", \"Evaluated_On\", \"Accuracy\", \"Class\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "    for (trained_on, evaluated_on), metrics in results.items():\n",
    "        for cls, cls_metrics in metrics.items():\n",
    "            writer.writerow([trained_on, evaluated_on, metrics[\"accuracy\"], cls, cls_metrics[\"precision\"], cls_metrics[\"recall\"], cls_metrics[\"f1-score\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
