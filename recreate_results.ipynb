{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-seed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ===========================\n",
    "# 1. Set Random Seeds for Reproducibility\n",
    "# ===========================\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 2. Define Custom Dataset Class\n",
    "# ===========================\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading images from 'real' and 'synthetic' directories.\n",
    "    Assigns label 0 for 'real' and 1 for 'synthetic'.\n",
    "    \"\"\"\n",
    "    def __init__(self, real_dir, synthetic_dir, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif', '.gif')\n",
    "\n",
    "        for root, _, files in os.walk(real_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(supported_extensions):\n",
    "                    self.image_paths.append(os.path.join(root, file))\n",
    "                    self.labels.append(0)\n",
    "\n",
    "        for root, _, files in os.walk(synthetic_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(supported_extensions):\n",
    "                    self.image_paths.append(os.path.join(root, file))\n",
    "                    self.labels.append(1)\n",
    "\n",
    "        assert len(self.image_paths) == len(self.labels), \"Mismatch between images and labels\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "            label = -1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 3. Configuration and Hyperparameters\n",
    "# ===========================\n",
    "data_dir = \"data/stanford-cars/split_random/\"  # Update this path\n",
    "real_test_dir = os.path.join(data_dir, 'real', 'test')\n",
    "synthetic_test_dir = os.path.join(data_dir, 'synthetic', 'test')\n",
    "\n",
    "for dir_path in [real_test_dir, synthetic_test_dir]:\n",
    "    if not os.path.isdir(dir_path):\n",
    "        raise ValueError(f\"Directory does not exist: {dir_path}\")\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \\\n",
    "                    \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-transforms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 4. Data Transforms\n",
    "# ===========================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 5. Load Test Dataset and DataLoader\n",
    "# ===========================\n",
    "test_dataset = ImageDataset(real_dir=real_test_dir, \n",
    "                            synthetic_dir=synthetic_test_dir, \n",
    "                            transform=test_transform)\n",
    "\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "class_names = ['real', 'synthetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-initialization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 6. Initialize the Model and Load Saved Weights\n",
    "# ===========================\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model_path = 'models/resnet18_finetuned.pth'\n",
    "if not os.path.isfile(model_path):\n",
    "    raise FileNotFoundError(f\"Saved model not found at {model_path}\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 8. Evaluation on Test Set\n",
    "# ===========================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(dataloader_test, desc=\"Testing Phase\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = running_loss / len(test_dataset)\n",
    "test_acc = running_corrects.float() / len(test_dataset)\n",
    "print(f'Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 9. Confusion Matrix and Classification Report\n",
    "# ===========================\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix on Test Set')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 10. Visualize Sample Predictions\n",
    "# ===========================\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp * np.array(imagenet_std) + np.array(imagenet_mean), 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "test_iter = iter(dataloader_test)\n",
    "inputs, classes = next(test_iter)\n",
    "inputs = inputs.to(device)\n",
    "classes = classes.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(min(6, inputs.size(0))):\n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    inp = inputs.cpu().data[i]\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp * np.array(imagenet_std) + np.array(imagenet_mean), 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    ax.set_title(f'Predicted: {class_names[preds[i]]}\\nTrue: {class_names[classes[i]]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
